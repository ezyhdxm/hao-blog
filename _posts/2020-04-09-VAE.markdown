---
layout: post
title:  "VAE"
comments: true
date:   2020-04-09 18:15:07 +0800
tags: generative
---

> VAE由一个参数化后验分布 $$q(z \mid x)$$ 的 encoder 网络，一个先验分布 $$p(z)$$ 及一个分布为 $$p(x \mid z)$$ 的 decoder 构成。


<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

## 潜变量模型

### Why do we use LVMs?

AR模型在估计概率方面已经有了不错的结果，但是由于它不对分量假设任何独立性，在抽样的时候就需要耗费大量时间。如果说我们想研究的对象背后有一个生成的逻辑，每个分量都受到少量的潜在变量影响，在给定潜在变量时，观测样本分量都是条件独立的，那么我们就可以更快地抽样了。

### How to train LVMs?

假设我们有

$$\begin{aligned}
&z \sim p_{Z}(z)\\
&x \sim p_{\theta}(x | z)
\end{aligned}$$

基于此，我们可以计算样本$$x$$的似然函数。我们采用极大似然法来估计条件概率中的参数$$\theta$$，从而我们的优化问题为

$$\max _{\theta} \sum_{i} \log p_{\theta}\left(x^{(i)}\right)=\sum_{i} \log \sum_{z} p_{Z}(z) p_{\theta}\left(x^{(i)} \mid z\right)$$

当$$z$$只取少数几个值的时候，我们可以精确计算目标函数，而在$$z$$取值较多时，我们只能做近似。
## Importance Sampling

利用Importance Sampling我们可以近似我们的训练目标函数。那么什么样的分布是一个好的分布呢？显然如果使用后验分布$$p_{\theta}(z  \mid x^{i})$$，那我们事实上就是在最小化原始目标函数。Variational Approach原则就是找一个简单的参数分布$$q(z)$$，它与后验分布要尽可能接近。

衡量分布接近程度的一个标准是KL divergence，两个分布越接近，则KL散度越小。对于分布$$q(z)$$及$$p_{\theta}\left(z \mid x^{(i)}\right)$$，我们希望最小化KL散度

$$\begin{aligned}
&\quad\min _{q(z)} \mathrm{KL}\left(q(z) \mid p_{\theta}\left(z \mid x^{(i)}\right)\right)\\
&=  \min _{q(z)} \mathbb{E}_{z \sim q(z)} \log \left(\frac{q(z)}{p_{\theta}\left(z \mid x^{(i)}\right)}\right) \\
&=  \min _{q(z)} \mathbb{E}_{z \sim q(z)} \log \left(\frac{q(z)}{p_{\theta}\left(x^{(i)} \mid z\right) p_{Z}(z) / p_{\theta}\left(x^{(i)}\right)}\right)\\
&= \min _{q(z)} \mathbb{E}_{z \sim q(z)}\left[\log q(z)-\log p_{Z}(z)-\log p_{\theta}\left(x^{(i)} \mid z\right)\right]+\log p_{\theta}\left(x^{(i)}\right)\\
&=\min _{q(z)} \mathbb{E}_{z \sim q(z)}\left[\log q(z)-\log p_{Z}(z)-\log p_{\theta}\left(x^{(i)} \mid z\right)\right]+\text { 与 } z \text { 无关的常数 }
\end{aligned}
$$

注意到$$q(z)$$一般是高斯分布之类的简单分布，$$p_{Z}(z)$$是相对简单的分布，而$$p_{\theta}\left(x^{(i)} \mid z\right)$$一般由一个神经网络来估计，所以这个目标函数是相对容易优化的。需要留意的是，我们这里为每一个$$x^{(i)}$$都找了一个$$q(z)$$，这个计算量是很大的，似乎也没太大必要。我们可以考虑这个优化问题的Amortized formulation，即

$$\min _{\phi} \sum_{i} \mathrm{KL}\left(q_{\phi}\left(z \mid x^{(i)}\right) \| p_{\theta}\left(z \mid x^{(i)}\right)\right)$$

这里的$$q_{\phi}\left(z \mid x^{(i)}\right)$$由神经网络给出，比如说$$q_{\phi}(z \mid x)=\mathcal{N}\left(\mu_{\phi}(x), \sigma_{\phi}^{2}(x)\right)$$，其中的均值与方差都由关于$$x$$的神经网络学习而得。

这样我们就得到了我们的第一个VAE，即IWAE（Importance Weighted AutoEncoder）。
## VLB


## Likelihood Ratio Gradient

让我们考虑优化问题

$$\max_{\Phi} \mathbb{E}_{z \sim q_{\Phi}(z)} \left(f(z)\right)$$

我们很想从分布$$q_{\Phi}(z)$$中进行抽样，然后使用梯度下降的方式来进行优化。但由于要优化的参数在抽样分布上，一旦我们结束抽样，剩下的部分里参数无迹可寻，我们也就无法使用梯度下降了。那让我们先稍微进行一些运算，有

$$\begin{aligned}
&\quad \nabla_{\phi} \int q_{\phi}(z)f(z)dz \\
&= \int \frac{q_{\phi}(z)}{q_{\phi}(z)}\nabla_{\phi} q_{\phi}(z)f(z)dz\\ 
&= \int q_{\phi}(z)\nabla_{\phi}\log \left(q_{\phi}(z)\right)f(z)dz\\
&= \mathbb{E}_{z \sim q_{\Phi}(z)} \left[\nabla_{\phi}\log \left(q_{\phi}(z)\right)f(z)\right]
\end{aligned}$$

于是我们可以考虑还从分布$$q_{\Phi}(z)$$中抽样，计算的梯度为$$\nabla_{\phi} \log \left(q_{\phi}(z)\right) f(z)$$。假设我们抽取了$$K$$个样本，那么样本的似然比梯度估计量为

$$\frac{1}{K}\sum_{i=1}^{K}\nabla_{\phi} \log \left(q_{\phi}(z^{(i)})\right) f(z^{(i)})$$

## VQ-VAE

VQ-VAE考虑使用离散潜变量及一种新的训练方式。后验与先验分布都是关于类别变量的，从这些分布中抽取的样本被视为一个嵌入表（embedding table）的下标。这些嵌入被用作为解码器网络的输入。

### Discrete Latent Variable

设$$K$$为离散潜在空间的大小（即潜在类别变量一共有$$K$$个类），$$D$$为每个潜嵌入向量（latent embedding vector）$$e_i$$的维数。模型接受到输入$$x$$后会将它先传入一个编码器，得到$$z_e(x)$$，并随后得到离散潜变量$$z$$

$$\begin{equation}q(z=k | x)=\left\{\begin{array}{ll}
1 & \text { for } k=\operatorname{argmin}_{j}\left\|z_{e}(x)-e_{j}\right\|_{2} \\
0 & \text { otherwise }
\end{array}\right. \tag{1}\label{eq:1}\end{equation}$$

解码器的输入则由$$z_q(x)$$给出

$$
\begin{equation}z_{q}(x)=e_{k}, \quad \text { where } \quad k=\operatorname{argmin}_{j}\left\|z_{e}(x)-e_{j}\right\|_{2} \tag{2}\label{eq:2}\end{equation}
$$

整个模型的全部参数由编码器、解码器及全体嵌入向量构成。

![VQ-VAE structure]({{ '/assets/images/VQ-VAE-f1.png' | relative_url }})
{: class="center"}
*fig.1.  左侧： VQ-VAE结构示意图； 右侧： 嵌入空间可视化示意图*

### Learning

整个模型的损失函数为

$$\begin{equation}L=\log p\left(x | z_{q}(x)\right)+\left\|\operatorname{sg}\left[z_{e}(x)\right]-e\right\|_{2}^{2}+\beta\left\|z_{e}(x)-\operatorname{sg}[e]\right\|_{2}^{2}\end{equation}$$

其中$$sg$$ 代表**停止梯度**（stopgradient）算符。在前向计算之中，它是恒等映射；而在反向梯度计算中，它的梯度为零。引入这个算符是由于方程\eqref{eq:2}没有实际的梯度，因此在反向传播的时候我们想仿照STE（Straight Through Estimator）的做法，直接将解码器输入$$z_q(x)$$处得到的梯度复制到编码器输出$$z_e(x)$$处；同时我们又想端到端地学习全体嵌入向量$$e$$，因此使用字典学习（Dictionary Learning）中的 VQ（Vector Quantisation）算法。

---

*If you notice mistakes and errors in this post, don't hesitate to contact me at [yh513447952 at outlook dot com] and I would be super happy to correct them right away!*
